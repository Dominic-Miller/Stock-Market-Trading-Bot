{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take in the processed ticker data from Trading_Signals.py and training windows from O_U.py\n",
    "# Trains the Model and creates a backtesting framework\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import scipy.stats\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded for: GOOG\n",
      "Data loaded for: GOOGL\n"
     ]
    }
   ],
   "source": [
    "# The first thing we need to do is to pull in our processed data on our target stocks:\n",
    "\n",
    "# Get the user's path to the folder we want to read the data from\n",
    "temp_path = os.path.abspath(os.path.dirname('path3.txt'))\n",
    "idx = temp_path.find('Stock-Market-Trading-Bot')\n",
    "path = temp_path[:(idx+24)]\n",
    "pathname = path + '/Source-Code/Backend/Data/Processed_Dump/'\n",
    "\n",
    "# Get the name of the stock\n",
    "stockName = input(\"Name for this stock: \")\n",
    "\n",
    "# Take in the two ticker names for the two stocks and load in the processed data\n",
    "classA = input(\"Ticker name for the first class: \")\n",
    "filename = pathname + classA + '_processed.csv'\n",
    "data1 = pd.read_csv(filename).iloc[:, 1:]\n",
    "classB = input(\"Ticker name for the second class: \")\n",
    "filename = pathname + classB + '_processed.csv'\n",
    "data2 = pd.read_csv(filename).iloc[:, 1:]\n",
    "print(\"Data loaded for: \" + classA)\n",
    "print(\"Data loaded for: \" + classB)\n",
    "\n",
    "# Load in info data\n",
    "infoPath = path + '/Source-Code/Backend/Data/Info/'\n",
    "#print(infoPath + stockName + '_info.npy')\n",
    "info = np.load(infoPath + stockName + '_info.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next thing we will need to do is create a dataframe where we can display our profits\n",
    "# and losses so we can track our net profit over time:\n",
    "\n",
    "def profit_loss_dataframe(ticker1, ticker2, info):\n",
    "\n",
    "    classA = ticker1['TICKER'].iloc[0]\n",
    "    classB = ticker2['TICKER'].iloc[0]\n",
    "\n",
    "    dataframe = pd.DataFrame()\n",
    "    dataframe_labels = pd.Series()\n",
    "\n",
    "    for i in info:\n",
    "        idx = i['test']['index']\n",
    "        residuals = i['test']['residuals_transform_price']\n",
    "        beta = i['train']['beta_fit_price']\n",
    "        df_temp = pd.concat([ticker1.loc[idx]['CLOSE'], beta * ticker2.loc[idx]['CLOSE'], ticker1.loc[idx]['price'],\n",
    "                             beta * ticker2.loc[idx]['price'], i['test']['residuals_transform_price'], ticker1.loc[idx]['TIME']], axis = 1)\n",
    "        dataframe = pd.concat([dataframe, df_temp], axis=0)\n",
    "        dataframe_labels = pd.concat([dataframe_labels, i['test']['labels']], axis=0)\n",
    "\n",
    "    dataframe['label'] = dataframe_labels\n",
    "    dataframe.columns = [classA, 'beta*' + classB, classA + '_return', 'beta*' + classB + '_return', 'residual', 'TIME', 'label']\n",
    "\n",
    "    # Find the profit or loss of the last trade\n",
    "    dataframe['beta*' + classB + '_gains'] = dataframe['beta*' + classB] - (1 - dataframe['beta*' + classB + '_return']) * dataframe['beta*' + classB]\n",
    "    dataframe[classA + '_gains'] = dataframe[classA] - (1 - dataframe[classA + '_return']) * dataframe[classA]\n",
    "    dataframe['profit'] = dataframe['beta*' + classB + '_gains'] - dataframe[classA + '_gains']\n",
    "    \n",
    "    \"\"\"for i, item in enumerate(dataframe['TIME']):\n",
    "        dataframe.loc[i, 'TIME'] = pd.to_datetime(item)\"\"\"\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All we have left before training our bot is to define a few more functions which will\n",
    "# modify our datasets to be exactly how we need it for training:\n",
    "\n",
    "# This function will find an SVM that will work based on the parameters dictionary:\n",
    "def find_svm(param_dict, info):\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for i in info:\n",
    "        temp_svm = svm.SVC(**param_dict)\n",
    "        temp_svm.fit(i['train']['ds_scale'], i['train']['labels'])\n",
    "        label = temp_svm.predict(i['test']['ds_scale'])\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.hstack(labels)\n",
    "\n",
    "# This next function will format a dictionary of parameters into a single string that can \n",
    "# be written to a file:\n",
    "def format_parameters(param_dict):\n",
    "    param = ', '.join(\"{!s}-{!r}\".format(key, val) for (key, val) in param_dict.items())\n",
    "    param = param.replace(\"{\", \"\")\n",
    "    param = param.replace(\"}\", \"\")\n",
    "    param = param.replace(\"'\", \"\")\n",
    "    param = param.replace(\",\", \"\")\n",
    "    param = param.replace(\" \", \"\")\n",
    "    param = param.replace(\":\", \"\")\n",
    "    param = param.replace(\".\", \"\")\n",
    "    param = param.strip()\n",
    "\n",
    "    return param\n",
    "\n",
    "# This next function will find the sharpe of our profit/loss dataframe:\n",
    "def find_sharpe(df):\n",
    "    days = {}\n",
    "    count = 0\n",
    "    for i, time in enumerate(df['TIME']):\n",
    "        time = pd.to_datetime(time)\n",
    "        time = time.date()\n",
    "        time = time.strftime('%m/%d/%Y')\n",
    "        number = df.iloc[i]['profit_timeline']\n",
    "        if time in days.keys():\n",
    "            days[time] = number + days[time]\n",
    "        else:\n",
    "            count += 1\n",
    "            days[time] = number\n",
    "    df = pd.DataFrame.from_dict(days, orient='index')\n",
    "    \n",
    "    sharpe = (df.mean() / df.std()) * np.sqrt(252)\n",
    "    return sharpe\n",
    "\n",
    "# This next function is a quick function to find the precision:\n",
    "def find_precision(labels, label):\n",
    "    precision = labels[np.logical_and(labels == 1, label == 1)].shape[0]/labels[labels == 1].shape[0]\n",
    "    return precision \n",
    "\n",
    "# This next function will find the sortino ratio of our profit/loss dataframe:\n",
    "def find_ratio(df):\n",
    "    days = {}\n",
    "    count = 0\n",
    "    for i , time in enumerate(df['TIME']):\n",
    "        time = pd.to_datetime(time)\n",
    "        time = time.date()\n",
    "        time = time.strftime('%m/%d/%Y')\n",
    "        number = df.iloc[i]['profit_timeline']\n",
    "        if time in days.keys():\n",
    "            days[time] = number + days[time]\n",
    "        else:\n",
    "            count += 1\n",
    "            days[time] = number\n",
    "\n",
    "    df = pd.DataFrame.from_dict(days, orient='index')\n",
    "\n",
    "    ratio = (df.mean() / df[df < 0].std()) * np.sqrt(252)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This final function will perform our profit/loss backtesting and give our prediction\n",
    "# labels which will then be used to tell the bot if it is correct or not:\n",
    "def backtesting(df, label, params):\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    param_str = format_parameters(params)\n",
    "    profit = 0.0\n",
    "\n",
    "    profit_timeline = []\n",
    "    trade_timeline = []\n",
    "    held_timeline = []\n",
    "    data = []\n",
    "\n",
    "    temp_df = df.copy()\n",
    "    temp_df['label'] = label\n",
    "\n",
    "    # Iterate through our dataframe\n",
    "    for row in temp_df.iterrows():\n",
    "        cur_profit = 0.0\n",
    "        profit = row[1]['profit']\n",
    "        residual = row[1]['residual']\n",
    "\n",
    "        # Iterate through our trading data\n",
    "        # We will use a window of 10 and threshold of 0.001\n",
    "        for position in data:\n",
    "            position['fresh'] += 1\n",
    "            position['profit'] += profit\n",
    "            if(position['residual'] - 0.001 >= residual) or position['fresh'] >= 10:\n",
    "                cur_profit += position['profit']\n",
    "                trade_timeline.append(position['profit'])\n",
    "                held_timeline.append(position['fresh'])\n",
    "                data.remove(position)\n",
    "        profit_timeline.append(cur_profit)\n",
    "        profit += cur_profit\n",
    "\n",
    "        if row[1]['label'] == 1 and residual > 0:\n",
    "            data.append({'profit': 0, 'residual': residual, 'fresh': 0})\n",
    "        \n",
    "    temp_df['profit_timeline'] = profit_timeline\n",
    "\n",
    "    # Add all of our necessary collumns to our returning profit/loss dataframe\n",
    "    results['total_profit'] = profit\n",
    "    results['daily_profit_timeline'] = profit_timeline\n",
    "    results['trade_profit_timeline'] = trade_timeline\n",
    "    results['time_held_timeline'] = held_timeline\n",
    "    results['trades_executed'] = len(trade_timeline)\n",
    "    results['params'] = params\n",
    "    results['precision'] = find_precision(temp_df['label'], df['label'])\n",
    "    results['mean_profit_per_trade'] = np.mean(trade_timeline)\n",
    "    results['sharpe'] = find_sharpe(temp_df)\n",
    "    results['sortino'] = find_ratio(temp_df)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOOG</th>\n",
       "      <th>beta*GOOGL</th>\n",
       "      <th>GOOG_return</th>\n",
       "      <th>beta*GOOGL_return</th>\n",
       "      <th>residual</th>\n",
       "      <th>TIME</th>\n",
       "      <th>label</th>\n",
       "      <th>beta*GOOGL_gains</th>\n",
       "      <th>GOOG_gains</th>\n",
       "      <th>profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>2674.230</td>\n",
       "      <td>2111.954114</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>15:31:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.634090</td>\n",
       "      <td>5.732261</td>\n",
       "      <td>-4.098171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2673.700</td>\n",
       "      <td>2111.847449</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000158</td>\n",
       "      <td>15:32:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.084273</td>\n",
       "      <td>-0.529895</td>\n",
       "      <td>0.445621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2674.880</td>\n",
       "      <td>2110.875609</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>-0.000364</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>15:33:00.000</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.767511</td>\n",
       "      <td>1.180521</td>\n",
       "      <td>-1.948031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>2671.490</td>\n",
       "      <td>2108.181322</td>\n",
       "      <td>-0.001267</td>\n",
       "      <td>-0.001008</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>15:34:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.126076</td>\n",
       "      <td>-3.385704</td>\n",
       "      <td>1.259627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>2670.950</td>\n",
       "      <td>2108.205025</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000211</td>\n",
       "      <td>15:35:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018729</td>\n",
       "      <td>-0.539891</td>\n",
       "      <td>0.558619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99043</th>\n",
       "      <td>89.775</td>\n",
       "      <td>86.704042</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>20:54:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061499</td>\n",
       "      <td>0.085081</td>\n",
       "      <td>-0.023581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99044</th>\n",
       "      <td>89.815</td>\n",
       "      <td>86.772106</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>-0.000318</td>\n",
       "      <td>20:55:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066234</td>\n",
       "      <td>0.040018</td>\n",
       "      <td>0.026216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99045</th>\n",
       "      <td>89.680</td>\n",
       "      <td>86.631116</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>-0.001580</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>20:56:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.136868</td>\n",
       "      <td>-0.134797</td>\n",
       "      <td>-0.002071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99046</th>\n",
       "      <td>89.730</td>\n",
       "      <td>86.665148</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>20:57:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.033104</td>\n",
       "      <td>0.050028</td>\n",
       "      <td>-0.016924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99047</th>\n",
       "      <td>89.745</td>\n",
       "      <td>86.679733</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>20:58:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.015003</td>\n",
       "      <td>-0.000818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97048 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           GOOG   beta*GOOGL  GOOG_return  beta*GOOGL_return  residual  \\\n",
       "2000   2674.230  2111.954114     0.002144           0.000774  0.001370   \n",
       "2001   2673.700  2111.847449    -0.000198          -0.000040 -0.000158   \n",
       "2002   2674.880  2110.875609     0.000441          -0.000364  0.000805   \n",
       "2003   2671.490  2108.181322    -0.001267          -0.001008 -0.000259   \n",
       "2004   2670.950  2108.205025    -0.000202           0.000009 -0.000211   \n",
       "...         ...          ...          ...                ...       ...   \n",
       "99043    89.775    86.704042     0.000948           0.000709  0.000238   \n",
       "99044    89.815    86.772106     0.000446           0.000763 -0.000318   \n",
       "99045    89.680    86.631116    -0.001503          -0.001580  0.000077   \n",
       "99046    89.730    86.665148     0.000558           0.000382  0.000176   \n",
       "99047    89.745    86.679733     0.000167           0.000164  0.000004   \n",
       "\n",
       "               TIME  label  beta*GOOGL_gains  GOOG_gains    profit  \n",
       "2000   15:31:00.000      1          1.634090    5.732261 -4.098171  \n",
       "2001   15:32:00.000      0         -0.084273   -0.529895  0.445621  \n",
       "2002   15:33:00.000      1         -0.767511    1.180521 -1.948031  \n",
       "2003   15:34:00.000      0         -2.126076   -3.385704  1.259627  \n",
       "2004   15:35:00.000      0          0.018729   -0.539891  0.558619  \n",
       "...             ...    ...               ...         ...       ...  \n",
       "99043  20:54:00.000      0          0.061499    0.085081 -0.023581  \n",
       "99044  20:55:00.000      0          0.066234    0.040018  0.026216  \n",
       "99045  20:56:00.000      0         -0.136868   -0.134797 -0.002071  \n",
       "99046  20:57:00.000      0          0.033104    0.050028 -0.016924  \n",
       "99047  20:58:00.000      0          0.014184    0.015003 -0.000818  \n",
       "\n",
       "[97048 rows x 10 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will call these functions to create our dataframe and display our profits:\n",
    "\n",
    "pl_df = profit_loss_dataframe(data1, data2, info)\n",
    "pl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before training our model, we must set some parameters first:\n",
    "\n",
    "params = {'C': 100,\n",
    "          'cache_size': 2000,\n",
    "          'class_weight': {0: 0.5, 1: 0.5},\n",
    "          'gamma': 1,\n",
    "          'kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Now we can fit our SVM model which will result in our trained bot:\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m Bot \u001b[38;5;241m=\u001b[39m \u001b[43mfind_svm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m pl_info \u001b[38;5;241m=\u001b[39m backtesting(pl_df, Bot, info)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(pl_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_profit\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[85], line 12\u001b[0m, in \u001b[0;36mfind_svm\u001b[0;34m(param_dict, info)\u001b[0m\n\u001b[1;32m     10\u001b[0m     temp_svm \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mSVC(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam_dict)\n\u001b[1;32m     11\u001b[0m     temp_svm\u001b[38;5;241m.\u001b[39mfit(i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds_scale\u001b[39m\u001b[38;5;124m'\u001b[39m], i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[43mtemp_svm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mds_scale\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mhstack(labels)\n",
      "File \u001b[0;32m~/anaconda3/envs/poke/lib/python3.11/site-packages/sklearn/svm/_base.py:818\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    816\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 818\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[0;32m~/anaconda3/envs/poke/lib/python3.11/site-packages/sklearn/svm/_base.py:431\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    416\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m     predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[0;32m~/anaconda3/envs/poke/lib/python3.11/site-packages/sklearn/svm/_base.py:611\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    608\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[0;32m--> 611\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m    621\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[0;32m~/anaconda3/envs/poke/lib/python3.11/site-packages/sklearn/base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    603\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 605\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    607\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/anaconda3/envs/poke/lib/python3.11/site-packages/sklearn/utils/validation.py:957\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    952\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    953\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    954\u001b[0m         )\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 957\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    965\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/envs/poke/lib/python3.11/site-packages/sklearn/utils/validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/poke/lib/python3.11/site-packages/sklearn/utils/validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nSVC does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Now we can fit our SVM model which will result in our trained bot:\n",
    "\n",
    "Bot = find_svm(params, info)\n",
    "Bot_info = backtesting(pl_df, Bot, info)\n",
    "print(Bot_info['total_profit'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poke",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
