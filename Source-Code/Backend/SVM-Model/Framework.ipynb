{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take in the processed ticker data from Trading_Signals.py and training windows from O_U.py\n",
    "# Trains the Model and creates a backtesting framework\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import scipy.stats\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded for: GOOG\n",
      "Data loaded for: GOOGL\n"
     ]
    }
   ],
   "source": [
    "# The first thing we need to do is to pull in our processed data on our target stocks:\n",
    "\n",
    "# Get the user's path to the folder we want to read the data from\n",
    "temp_path = os.path.abspath(os.path.dirname('path3.txt'))\n",
    "idx = temp_path.find('Stock-Market-Trading-Bot')\n",
    "path = temp_path[:(idx+24)]\n",
    "pathname = path + '/Source-Code/Backend/Data/Processed_Dump/'\n",
    "\n",
    "# Get the name of the stock\n",
    "stockName = input(\"Name for this stock: \")\n",
    "\n",
    "# Take in the two ticker names for the two stocks and load in the processed data\n",
    "classA = input(\"Ticker name for the first class: \")\n",
    "filename = pathname + classA + '_processed.csv'\n",
    "data1 = pd.read_csv(filename).iloc[:, 1:]\n",
    "classB = input(\"Ticker name for the second class: \")\n",
    "filename = pathname + classB + '_processed.csv'\n",
    "data2 = pd.read_csv(filename).iloc[:, 1:]\n",
    "print(\"Data loaded for: \" + classA)\n",
    "print(\"Data loaded for: \" + classB)\n",
    "\n",
    "# Load in info data\n",
    "infoPath = path + '/Source-Code/Backend/Data/Info/'\n",
    "#print(infoPath + stockName + '_info.npy')\n",
    "info = np.load(infoPath + stockName + '_info.npy', allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next thing we will need to do is create a dataframe where we can display our profits\n",
    "# and losses so we can track our net profit over time:\n",
    "\n",
    "def profit_loss_dataframe(ticker1, ticker2, info):\n",
    "\n",
    "    classA = ticker1['TICKER']\n",
    "    classB = ticker2['TICKER']\n",
    "\n",
    "    dataframe = pd.DataFrame()\n",
    "    dataframe_labels = pd.Series()\n",
    "\n",
    "    for i in info:\n",
    "        idx = i['test']['index']\n",
    "        residuals = i['test']['residuals_transform_price']\n",
    "        beta = i['train']['beta_fit_price']\n",
    "        df_temp = pd.concat([ticker1.loc[idx]['CLOSE'], beta * ticker2.loc[idx]['CLOSE'], ticker1.loc[idx]['price'],\n",
    "                             beta * ticker2.loc[idx]['price'], i['test']['residuals_transform_price'], ticker1.loc[idx]['TIMESTAMP']], axis=1)\n",
    "        datafram = dataframe.append(df_temp)\n",
    "        dataframe_labels = dataframe_labels.append(i['test']['labels'])\n",
    "\n",
    "    dataframe['label'] = dataframe_labels\n",
    "    dataframe.columns = [classA, 'beta*' + classB, classA + '_return', 'beta*' + classB + '_return', 'residual', 'TIMESTAMP', 'label']\n",
    "\n",
    "    # Find the profit or loss of the last trade\n",
    "    dataframe['beta*' + classB + '_gains'] = dataframe['beta*' + classB] - (1 - dataframe['beta*' + classB + '_return']) * dataframe['beta*' + classB]\n",
    "    dataframe[classA + '_gains'] = dataframe[classA] - (1 - dataframe[classA + '_return']) * dataframe[classA]\n",
    "    dataframe['profit'] = dataframe['beta*' + classB + '_gains'] - dataframe[classA + '_gains']\n",
    "    for i, item in enumerate(dataframe['TIMESTAMP']):\n",
    "        dataframe.loc[i, 'TIMESTAMP'] = pd.to_datetime(item)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All we have left before training our bot is to define a few more functions which will\n",
    "# modify our datasets to be exactly how we need it for training:\n",
    "\n",
    "# This function will find an SVM that will work based on the parameters dictionary:\n",
    "def find_svm(param_dict, info):\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for i in info:\n",
    "        temp_svm = svm.SVC(**param_dict)\n",
    "        temp_svm.fit(i['train']['df_scale'], i['train']['labels'])\n",
    "        label = temp_svm.predict(i['test']['df_scale'])\n",
    "        labels.append(label)\n",
    "\n",
    "    return np.hstack(labels)\n",
    "\n",
    "# This next function will format a dictionary of parameters into a single string that can \n",
    "# be written to a file:\n",
    "def format_parameters(param_dict):\n",
    "    param = ', '.join(\"{!s}-{!r}\".format(key, val) for (key, val) in param_dict.items())\n",
    "    param = param.replace(\"{\", \"\")\n",
    "    param = param.replace(\"}\", \"\")\n",
    "    param = param.replace(\"'\", \"\")\n",
    "    param = param.replace(\",\", \"\")\n",
    "    param = param.replace(\" \", \"\")\n",
    "    param = param.replace(\":\", \"\")\n",
    "    param = param.replace(\".\", \"\")\n",
    "    param = param.strip()\n",
    "\n",
    "    return param\n",
    "\n",
    "# This next function will find the sharpe of our profit/loss dataframe:\n",
    "def find_sharpe(df):\n",
    "    days = {}\n",
    "    count = 0\n",
    "    for i, time in enumerate(df['TIMESTAMP']):\n",
    "        time = pd.to_datetime(time)\n",
    "        time = time.date()\n",
    "        time = time.strftime('%m/%d/%Y')\n",
    "        number = df.iloc[i]['profit_timeline']\n",
    "        if time in days.keys():\n",
    "            days[time] = number + days[time]\n",
    "        else:\n",
    "            count += 1\n",
    "            days[time] = number\n",
    "    df = pd.DataFrame.from_dict(days, orient='index')\n",
    "    \n",
    "    sharpe = (df.mean() / df.std()) * np.sqrt(252)\n",
    "    return sharpe\n",
    "\n",
    "# This next function is a quick function to find the precision:\n",
    "def find_precision(labels, label):\n",
    "    precision = labels[np.logical_and(labels == 1, label == 1)].shape[0]/labels[labels == 1].shape[0]\n",
    "    return precision \n",
    "\n",
    "# This next function will find the sortino ratio of our profit/loss dataframe:\n",
    "def find_ratio(df):\n",
    "    days = {}\n",
    "    count = 0\n",
    "    for i , time in enumerate(df['TIMESTAMP']):\n",
    "        time = pd.to_datetime(time)\n",
    "        time = time.date()\n",
    "        time = time.strftime('%m/%d/%Y')\n",
    "        number = df.iloc[i]['profit_timeline']\n",
    "        if time in days.keys():\n",
    "            days[time] = number + days[time]\n",
    "        else:\n",
    "            count += 1\n",
    "            days[time] = number\n",
    "\n",
    "    df = pd.DataFrame.from_dict(days, orient='index')\n",
    "\n",
    "    ratio = (df.mean() / df[df < 0].std()) * np.sqrt(252)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This final function will perform our profit/loss backtesting and give our prediction\n",
    "# labels which will then be used to tell the bot if it is correct or not:\n",
    "def backtesting(df, label, params):\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    param_str = format_parameters(params)\n",
    "    profit = 0.0\n",
    "\n",
    "    profit_timeline = []\n",
    "    trade_timeline = []\n",
    "    held_timeline = []\n",
    "    data = []\n",
    "\n",
    "    temp_df = df.copy()\n",
    "    temp_df['label'] = label\n",
    "\n",
    "    # Iterate through our dataframe\n",
    "    for row in temp_df.iterrows():\n",
    "        cur_profit = 0.0\n",
    "        profit = row[1]['profit']\n",
    "        residual = row[1]['residual']\n",
    "\n",
    "        # Iterate through our trading data\n",
    "        # We will use a window of 10 and threshold of 0.001\n",
    "        for position in data:\n",
    "            position['fresh'] += 1\n",
    "            position['profit'] += profit\n",
    "            if(position['residual'] - 0.001 >= residual) or position['fresh'] >= 10:\n",
    "                cur_profit += position['profit']\n",
    "                trade_timeline.append(position['profit'])\n",
    "                held_timeline.append(position['fresh'])\n",
    "                data.remove(position)\n",
    "        profit_timeline.append(cur_profit)\n",
    "        profit += cur_profit\n",
    "\n",
    "        if row[1]['label'] == 1 and residual > 0:\n",
    "            data.append({'profit': 0, 'residual': residual, 'fresh': 0})\n",
    "        \n",
    "    temp_df['profit_timeline'] = profit_timeline\n",
    "\n",
    "    # Add all of our necessary collumns to our returning profit/loss dataframe\n",
    "    results['total_profit'] = profit\n",
    "    results['daily_profit_timeline'] = profit_timeline\n",
    "    results['trade_profit_timeline'] = trade_timeline\n",
    "    results['time_held_timeline'] = held_timeline\n",
    "    results['trades_executed'] = len(trade_timeline)\n",
    "    results['params'] = params\n",
    "    results['precision'] = find_precision(temp_df['label'], df['label'])\n",
    "    results['mean_profit_per_trade'] = np.mean(trade_timeline)\n",
    "    results['sharpe'] = find_sharpe(temp_df)\n",
    "    results['sortino'] = find_ratio(temp_df)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before creating our dataframe, we need to set our parameters:\n",
    "\n",
    "params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'TIMESTAMP'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/poke/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TIMESTAMP'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Now we will call these functions to create our dataframe and display our profits:\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m pl_df \u001b[38;5;241m=\u001b[39m \u001b[43mprofit_loss_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m, in \u001b[0;36mprofit_loss_dataframe\u001b[0;34m(ticker1, ticker2, info)\u001b[0m\n\u001b[1;32m     14\u001b[0m residuals \u001b[38;5;241m=\u001b[39m i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresiduals_transform_price\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m beta \u001b[38;5;241m=\u001b[39m i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta_fit_price\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m df_temp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([ticker1\u001b[38;5;241m.\u001b[39mloc[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCLOSE\u001b[39m\u001b[38;5;124m'\u001b[39m], beta \u001b[38;5;241m*\u001b[39m ticker2\u001b[38;5;241m.\u001b[39mloc[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCLOSE\u001b[39m\u001b[38;5;124m'\u001b[39m], ticker1\u001b[38;5;241m.\u001b[39mloc[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m---> 17\u001b[0m                      beta \u001b[38;5;241m*\u001b[39m ticker2\u001b[38;5;241m.\u001b[39mloc[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m], i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresiduals_transform_price\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[43mticker1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTIMESTAMP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m datafram \u001b[38;5;241m=\u001b[39m dataframe\u001b[38;5;241m.\u001b[39mappend(df_temp)\n\u001b[1;32m     19\u001b[0m dataframe_labels \u001b[38;5;241m=\u001b[39m dataframe_labels\u001b[38;5;241m.\u001b[39mappend(i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/poke/lib/python3.11/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/poke/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TIMESTAMP'"
     ]
    }
   ],
   "source": [
    "# Now we will call these functions to create our dataframe and display our profits:\n",
    "\n",
    "pl_df = profit_loss_dataframe(data1, data2, info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poke",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
